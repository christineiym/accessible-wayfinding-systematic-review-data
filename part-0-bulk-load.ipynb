{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Bulk Loading BibTeX data\n",
    "\n",
    "Load data from a .bib file into an sqlite database.\n",
    "\n",
    "Based on the [documentation of the BibTexParser Python package](https://bibtexparser.readthedocs.io/en/master/tutorial.html#step-2-parse-it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christine Mendoza, \\\n",
    "    with some sqlite3-related code from Dr. Gary Bishop's / Dr. John Majikes' UNC Chapel Hill COMP421 (Databases) class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further, make sure to run the following commands in the terminal for package installation and restart if necessary:\n",
    "\n",
    "```pip install bibtexparser```\n",
    "\n",
    "```pip install sqlite3```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also make sure to edit your file paths as necessary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_BIB_DATA: str = \"./data/paper-selection-analysis/part-0.bib\"\n",
    "OUTPUT_DB: str = \"./data/sqlite/analysis.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Parse BibTeX data\n",
    "\n",
    "NOTE: The BiBTeX file should not have any spaces in its fields (possible with Scopus for fields related to funding), and duplicate fields should not be present in entries. Please ensure the file is formed properly before parsing, or entries will be omitted. I chose to omit the fields on funding_details and funding_text entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "import bibtexparser\n",
    "\n",
    "with open(RAW_BIB_DATA) as bibtex_file:\n",
    "    bib_to_dict = bibtexparser.load(bibtex_file)\n",
    "\n",
    "# Check that the number of entries loaded in is as expected.\n",
    "print(len(bib_to_dict.entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Determine columns for part 0 sqlite database\n",
    "\n",
    "Not all BibTeX entries have the same columns. If you do not know the columns you would like in the database in advance, you will have to determine this from the columns present in the BibTeX data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'journal', 'chemicals_cas', 'issn', 'number', 'volume', 'language', 'references', 'pubmed_id', 'document_type', 'sponsors', 'publisher', 'coden', 'author_keywords', 'abbrev_source_title', 'year', 'page_count', 'affiliation', 'ENTRYTYPE', 'keywords', 'correspondence_address1', 'author', 'title', 'isbn', 'pages', 'ID', 'source', 'note', 'abstract', 'art_number', 'editor', 'doi', 'url'}\n"
     ]
    }
   ],
   "source": [
    "raw_columns: set = set([])\n",
    "\n",
    "for entry in bib_to_dict.entries:\n",
    "    current_keys: list[str] = entry.keys()\n",
    "\n",
    "    for key in current_keys:\n",
    "        raw_columns.add(key)\n",
    "\n",
    "# print result\n",
    "print(raw_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide on your columns, then edit `final_columns` below as necessary, keeping in mind reserved keywords in sql (ex. `references`). \n",
    "\n",
    "`final_columns` is currently assigned the value of `raw_columns`, with an edit to rename `references` to `paper_references`, if it exists in the `raw_columns` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'journal', 'chemicals_cas', 'issn', 'number', 'volume', 'language', 'pubmed_id', 'document_type', 'sponsors', 'publisher', 'coden', 'author_keywords', 'abbrev_source_title', 'year', 'page_count', 'affiliation', 'ENTRYTYPE', 'keywords', 'correspondence_address1', 'author', 'title', 'isbn', 'paper_references', 'pages', 'ID', 'source', 'note', 'abstract', 'art_number', 'editor', 'doi', 'url'}\n"
     ]
    }
   ],
   "source": [
    "final_columns: set = raw_columns\n",
    "\n",
    "if \"references\" in final_columns:\n",
    "    final_columns.remove(\"references\")\n",
    "    final_columns.add(\"paper_references\")\n",
    "\n",
    "# print result\n",
    "print(final_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create sqlite database and set up part 0 table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your database connection. A file with the path specified by `OUTPUT_DB` will automatically be created if one does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.Connection(OUTPUT_DB)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the process, I assume here that we're treating all columns in `final_columns` as text and join together the set elements to create a string. It's usually best practice to simply write out the schema yourself and to avoid string concatenation because of the risk of SQL injection. But since this is a local file, I am assuming no one else is tampering with this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE All_Papers(paper_analysis_id INTEGER PRIMARY KEY AUTOINCREMENT, journal TEXT, chemicals_cas TEXT, issn TEXT, number TEXT, volume TEXT, language TEXT, pubmed_id TEXT, document_type TEXT, sponsors TEXT, publisher TEXT, coden TEXT, author_keywords TEXT, abbrev_source_title TEXT, year TEXT, page_count TEXT, affiliation TEXT, ENTRYTYPE TEXT, keywords TEXT, correspondence_address1 TEXT, author TEXT, title TEXT, isbn TEXT, paper_references TEXT, pages TEXT, ID TEXT, source TEXT, note TEXT, abstract TEXT, art_number TEXT, editor TEXT, doi TEXT, url TEXT);\n"
     ]
    }
   ],
   "source": [
    "bibtex_fields = \" TEXT, \".join(final_columns)\n",
    "\n",
    "create_tables = \"\"\"CREATE TABLE All_Papers(paper_analysis_id INTEGER PRIMARY KEY AUTOINCREMENT, \"\"\" + bibtex_fields + \"\"\" TEXT);\"\"\"\n",
    "\n",
    "# print resulting (unformatted) query\n",
    "print(create_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create the table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fb95a107d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.executescript(create_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the table was actually created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is/are 1 table(s) in the database.\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('''\n",
    "               SELECT COUNT(*)\n",
    "               FROM sqlite_master\n",
    "               WHERE type='table' AND\n",
    "                     name NOT LIKE 'sqlite_%' ''')\n",
    "table_count = cursor.fetchone()[0]\n",
    "print(f'There is/are {table_count} table(s) in the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Actually bulk load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format each entry to match the table schema and insert it as a record into the part_0 table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume mutually exclusive access to the database.\n",
    "\n",
    "for current_entry in bib_to_dict.entries:\n",
    "    entry = current_entry.copy()\n",
    "\n",
    "    # format the entry to match the table schema\n",
    "    for key in final_columns:\n",
    "        if key not in entry:\n",
    "            entry[key] = \"\"\n",
    "    \n",
    "    \n",
    "    # I just wrote it all out this time, with a little help from regex\n",
    "    cursor.execute('''INSERT INTO All_Papers (correspondence_address1, number, doi, isbn, \n",
    "                        year, abbrev_source_title, editor, art_number, ID, pubmed_id, volume, \n",
    "                        coden, publisher, author, page_count, paper_references, issn, source, \n",
    "                        language, author_keywords, keywords, url, note, \n",
    "                        affiliation, pages, ENTRYTYPE, abstract, sponsors, document_type, \n",
    "                        title, journal) \n",
    "                    values (?, ?, ?, ?, ?,\n",
    "                            ?, ?, ?, ?, ?,\n",
    "                            ?, ?, ?, ?, ?,\n",
    "                            ?, ?, ?, ?, ?,\n",
    "                            ?, ?, ?, ?, ?,\n",
    "                            ?, ?, ?, ?, ?,\n",
    "                            ?)''',\n",
    "                    (entry['correspondence_address1'],\n",
    "                        entry['number'],\n",
    "                        entry['doi'],\n",
    "                        entry['isbn'],\n",
    "                        entry['year'],\n",
    "                        entry['abbrev_source_title'],\n",
    "                        entry['editor'],\n",
    "                        entry['art_number'],\n",
    "                        entry['ID'],\n",
    "                        entry['pubmed_id'],\n",
    "                        entry['volume'],\n",
    "                        entry['coden'],\n",
    "                        entry['publisher'],\n",
    "                        entry['author'],\n",
    "                        entry['page_count'],\n",
    "                        entry['paper_references'],\n",
    "                        entry['issn'],\n",
    "                        entry['source'],\n",
    "                        entry['language'],\n",
    "                        entry['author_keywords'],\n",
    "                        entry['keywords'],\n",
    "                        entry['url'],\n",
    "                        entry['note'],\n",
    "                        entry['affiliation'],\n",
    "                        entry['pages'],\n",
    "                        entry['ENTRYTYPE'],\n",
    "                        entry['abstract'],\n",
    "                        entry['sponsors'],\n",
    "                        entry['document_type'],\n",
    "                        entry['title'],\n",
    "                        entry['journal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your table. You should have the same amount of records in your table as you did entries in the original BibTeX file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "table_size: int = cursor.execute('''select count(*) from %s''' % \"All_Papers\").fetchone()[0]\n",
    "print(table_size)\n",
    "\n",
    "assert(table_size == len(bib_to_dict.entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Now that you have all the records loaded into a table in your database, you can proceed to the next part!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
